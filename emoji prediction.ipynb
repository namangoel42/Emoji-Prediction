{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emoji_dictionary={\n",
    "    \"0\":\"\\u2764\\uFE0F\",\n",
    "    \"1\":\":baseball:\",\n",
    "    \"2\":\":grinning_face_with_big_eyes:\",\n",
    "    \"3\":\":disappointed_face:\",\n",
    "    \"4\":\":fork_and_knife:\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòÉ\n",
      "üòû\n",
      "üç¥\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/91885/Python programs/train.csv',header=None)\n",
    "df1=pd.read_csv('C:/Users/91885/Python programs/test.csv',header=None)\n",
    "X=pd.DataFrame.to_numpy(df)\n",
    "X1=pd.DataFrame.to_numpy(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 0 2 0 0 0 4 2 1 3 3 2 1 3 3 2 3 4 0 2 4 3 3 3 3 0 2 0 0 1 3 2 0 1 2\n",
      " 4 4 2 2 2 0 1 2 0 2 2 2 3 3 0 3 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "x_train=X[:,1]\n",
    "y_train=X[:,2]\n",
    "x_test=X1[:,0]\n",
    "y_test=X1[:,1]\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÉ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(x_train[i],emoji.emojize(emoji_dictionary[str(y_train[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings={}\n",
    "f=open('glove.6B.50d.txt',encoding='utf-8')\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coeffs=np.asarray(values[1:],dtype='float')\n",
    "    word_embeddings[word]=coeffs\n",
    "    #print(word,coeffs)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 Converting sentence into a vector** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_output(X):\n",
    "    #X.shape[0] actually gives batch size or number of sentences\n",
    "    #ideally embedding_out should be (num_of_sentences*max_words_in_sentence*embedding of each word)\n",
    "    max_len=10\n",
    "    emb_dim=50\n",
    "    embedding_out=np.zeros((X.shape[0],max_len,emb_dim))\n",
    "    for ix in range(X.shape[0]):# X.shape[0] gives number of sentences\n",
    "        X[ix]=X[ix].split()\n",
    "        \n",
    "        for ij in range(len(X[ix])):\n",
    "            try:\n",
    "               embedding_out[ix][ij]=word_embeddings[X[ix][ij].lower()]\n",
    "            except:\n",
    "               embedding_out[ix][ij]=np.zeros((50,)) \n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix_train=embedding_output(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_matrix_test=embedding_output(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "#embeddings_matrix_train_y=embedding_output(y_train)\n",
    "print(embeddings_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** LSTM Architecture - Keras **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5)\n"
     ]
    }
   ],
   "source": [
    "y_train=to_categorical(y_train,num_classes=5)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 5)\n"
     ]
    }
   ],
   "source": [
    "y_test=to_categorical(y_test,num_classes=5)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 4s 42ms/step - loss: 1.6196 - acc: 0.2476 - val_loss: 1.5924 - val_acc: 0.2222\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 648us/step - loss: 1.5728 - acc: 0.3333 - val_loss: 1.5965 - val_acc: 0.2222\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 669us/step - loss: 1.5452 - acc: 0.4000 - val_loss: 1.6060 - val_acc: 0.2222\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 743us/step - loss: 1.5199 - acc: 0.3810 - val_loss: 1.6221 - val_acc: 0.2222\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 922us/step - loss: 1.4761 - acc: 0.4190 - val_loss: 1.6401 - val_acc: 0.2222\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 967us/step - loss: 1.4657 - acc: 0.4286 - val_loss: 1.6622 - val_acc: 0.2222\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 904us/step - loss: 1.4338 - acc: 0.4095 - val_loss: 1.6828 - val_acc: 0.1852\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 929us/step - loss: 1.4495 - acc: 0.3905 - val_loss: 1.6946 - val_acc: 0.1852\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 1.4121 - acc: 0.4381 - val_loss: 1.6955 - val_acc: 0.2222\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 639us/step - loss: 1.4252 - acc: 0.3714 - val_loss: 1.6762 - val_acc: 0.2222\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 660us/step - loss: 1.3840 - acc: 0.4857 - val_loss: 1.6362 - val_acc: 0.1852\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 803us/step - loss: 1.3456 - acc: 0.4476 - val_loss: 1.5917 - val_acc: 0.1852\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 642us/step - loss: 1.3027 - acc: 0.5143 - val_loss: 1.5524 - val_acc: 0.1852\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 729us/step - loss: 1.2588 - acc: 0.5143 - val_loss: 1.5186 - val_acc: 0.1852\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 830us/step - loss: 1.2161 - acc: 0.5333 - val_loss: 1.4941 - val_acc: 0.2593\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 783us/step - loss: 1.1843 - acc: 0.5143 - val_loss: 1.4681 - val_acc: 0.2963\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 651us/step - loss: 1.1262 - acc: 0.5333 - val_loss: 1.4266 - val_acc: 0.2963\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 754us/step - loss: 1.0614 - acc: 0.5810 - val_loss: 1.3892 - val_acc: 0.2963\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 901us/step - loss: 1.0456 - acc: 0.6190 - val_loss: 1.3561 - val_acc: 0.3704\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.9660 - acc: 0.6095 - val_loss: 1.3055 - val_acc: 0.3333\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.9357 - acc: 0.7143 - val_loss: 1.2394 - val_acc: 0.4444\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 868us/step - loss: 0.8977 - acc: 0.6762 - val_loss: 1.2115 - val_acc: 0.4444\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 720us/step - loss: 0.8148 - acc: 0.7429 - val_loss: 1.1951 - val_acc: 0.4815\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.7979 - acc: 0.7524 - val_loss: 1.1329 - val_acc: 0.4815\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.6766 - acc: 0.8000 - val_loss: 1.0967 - val_acc: 0.5185\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 881us/step - loss: 0.6566 - acc: 0.8095 - val_loss: 1.0936 - val_acc: 0.5556\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.6098 - acc: 0.7810 - val_loss: 1.0666 - val_acc: 0.5556\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 969us/step - loss: 0.6240 - acc: 0.8095 - val_loss: 1.0808 - val_acc: 0.6296\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 704us/step - loss: 0.5985 - acc: 0.8095 - val_loss: 1.2001 - val_acc: 0.5926\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 911us/step - loss: 0.4702 - acc: 0.8381 - val_loss: 1.3453 - val_acc: 0.5556\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 893us/step - loss: 0.4521 - acc: 0.8286 - val_loss: 1.2347 - val_acc: 0.5926\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3892 - acc: 0.8571 - val_loss: 1.1262 - val_acc: 0.5556\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 853us/step - loss: 0.4549 - acc: 0.8571 - val_loss: 1.0934 - val_acc: 0.6296\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 937us/step - loss: 0.4056 - acc: 0.8952 - val_loss: 1.2473 - val_acc: 0.5926\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 796us/step - loss: 0.4711 - acc: 0.8476 - val_loss: 1.2158 - val_acc: 0.5926\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 913us/step - loss: 0.5125 - acc: 0.8190 - val_loss: 1.0093 - val_acc: 0.6296\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 993us/step - loss: 0.4205 - acc: 0.8667 - val_loss: 1.0209 - val_acc: 0.6296\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 735us/step - loss: 0.4237 - acc: 0.8571 - val_loss: 1.0552 - val_acc: 0.6296\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 979us/step - loss: 0.3774 - acc: 0.8857 - val_loss: 1.2559 - val_acc: 0.5926\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3120 - acc: 0.8762 - val_loss: 1.4853 - val_acc: 0.5926\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3914 - acc: 0.8476 - val_loss: 1.2221 - val_acc: 0.5926\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2703 - acc: 0.9143 - val_loss: 1.0040 - val_acc: 0.6667\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2939 - acc: 0.9048 - val_loss: 0.9689 - val_acc: 0.7037\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 953us/step - loss: 0.3140 - acc: 0.8952 - val_loss: 0.8781 - val_acc: 0.6296\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 979us/step - loss: 0.2578 - acc: 0.9238 - val_loss: 1.0285 - val_acc: 0.6296\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2869 - acc: 0.9143 - val_loss: 1.1774 - val_acc: 0.6296\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 694us/step - loss: 0.2773 - acc: 0.9333 - val_loss: 1.1968 - val_acc: 0.6667\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 664us/step - loss: 0.2150 - acc: 0.9429 - val_loss: 1.3466 - val_acc: 0.5556\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 895us/step - loss: 0.1882 - acc: 0.9524 - val_loss: 1.2302 - val_acc: 0.6296\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 741us/step - loss: 0.1706 - acc: 0.9333 - val_loss: 1.1991 - val_acc: 0.5926\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 864us/step - loss: 0.2038 - acc: 0.9429 - val_loss: 1.1879 - val_acc: 0.5926\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 815us/step - loss: 0.2172 - acc: 0.9333 - val_loss: 1.1455 - val_acc: 0.5926\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 635us/step - loss: 0.1356 - acc: 0.9429 - val_loss: 1.2310 - val_acc: 0.6296\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 724us/step - loss: 0.1436 - acc: 0.9810 - val_loss: 1.2624 - val_acc: 0.6296\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 750us/step - loss: 0.2007 - acc: 0.9143 - val_loss: 1.0856 - val_acc: 0.6296\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 724us/step - loss: 0.1244 - acc: 0.9810 - val_loss: 1.0925 - val_acc: 0.5926\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 776us/step - loss: 0.1184 - acc: 0.9714 - val_loss: 1.1912 - val_acc: 0.5556\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 663us/step - loss: 0.1010 - acc: 0.9619 - val_loss: 1.2958 - val_acc: 0.5926\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1013 - acc: 0.9714 - val_loss: 1.4252 - val_acc: 0.5926\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0814 - acc: 0.9714 - val_loss: 1.4728 - val_acc: 0.5926\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 684us/step - loss: 0.0837 - acc: 0.9905 - val_loss: 1.5151 - val_acc: 0.6296\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 924us/step - loss: 0.0805 - acc: 0.9905 - val_loss: 1.4117 - val_acc: 0.6667\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 913us/step - loss: 0.0890 - acc: 0.9714 - val_loss: 1.4567 - val_acc: 0.5926\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 947us/step - loss: 0.0950 - acc: 0.9714 - val_loss: 1.5560 - val_acc: 0.5926\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 759us/step - loss: 0.0558 - acc: 0.9905 - val_loss: 1.5086 - val_acc: 0.6296\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 688us/step - loss: 0.0637 - acc: 0.9905 - val_loss: 1.5544 - val_acc: 0.6296\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 688us/step - loss: 0.0829 - acc: 0.9810 - val_loss: 1.5017 - val_acc: 0.6667\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 634us/step - loss: 0.0449 - acc: 0.9905 - val_loss: 1.3857 - val_acc: 0.5926\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 625us/step - loss: 0.0474 - acc: 0.9905 - val_loss: 1.3923 - val_acc: 0.6296\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 884us/step - loss: 0.0567 - acc: 0.9905 - val_loss: 1.4426 - val_acc: 0.5926\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 764us/step - loss: 0.0363 - acc: 1.0000 - val_loss: 1.5399 - val_acc: 0.6296\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 768us/step - loss: 0.0543 - acc: 0.9810 - val_loss: 1.7800 - val_acc: 0.5926\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 650us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 2.1452 - val_acc: 0.5926\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 909us/step - loss: 0.0340 - acc: 1.0000 - val_loss: 2.1924 - val_acc: 0.5926\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 907us/step - loss: 0.0485 - acc: 0.9905 - val_loss: 2.0713 - val_acc: 0.5185\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0450 - acc: 0.9810 - val_loss: 1.9849 - val_acc: 0.5556\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0578 - acc: 0.9810 - val_loss: 1.8138 - val_acc: 0.5185\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 926us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 1.5501 - val_acc: 0.5926\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 995us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 1.4806 - val_acc: 0.6296\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 750us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 1.5966 - val_acc: 0.6296\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 858us/step - loss: 0.0605 - acc: 0.9810 - val_loss: 1.5370 - val_acc: 0.6296\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 857us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 1.5515 - val_acc: 0.6667\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0315 - acc: 1.0000 - val_loss: 1.6076 - val_acc: 0.5926\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0802 - acc: 0.9810 - val_loss: 1.6681 - val_acc: 0.5556\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 966us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 1.7702 - val_acc: 0.6296\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0340 - acc: 0.9905 - val_loss: 1.8269 - val_acc: 0.5926\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 706us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 1.7261 - val_acc: 0.6296\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 748us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 1.6852 - val_acc: 0.5926\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 891us/step - loss: 0.0258 - acc: 1.0000 - val_loss: 1.6798 - val_acc: 0.5556\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 685us/step - loss: 0.0230 - acc: 0.9905 - val_loss: 1.7372 - val_acc: 0.5556\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 746us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 1.8243 - val_acc: 0.5556\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 685us/step - loss: 0.0281 - acc: 0.9905 - val_loss: 1.9143 - val_acc: 0.5556\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 643us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 2.0035 - val_acc: 0.5926\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 669us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 2.1403 - val_acc: 0.6296\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 680us/step - loss: 0.0227 - acc: 0.9905 - val_loss: 2.1763 - val_acc: 0.6296\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 867us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 2.2461 - val_acc: 0.5556\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 2.3087 - val_acc: 0.5556\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 2.3407 - val_acc: 0.5556\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 891us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.3561 - val_acc: 0.5185\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 852us/step - loss: 0.0215 - acc: 0.9905 - val_loss: 2.4421 - val_acc: 0.4815\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint=ModelCheckpoint(\"best_model.h5\",monitor='val_loss',verbose=True,save_best_only=True)\n",
    "earlystop=EarlyStopping(monitor='val_acc',patience=10)\n",
    "hist=model.fit(embeddings_matrix_train,y_train,epochs=100,batch_size=64,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = 'best_model.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-7bfe53192b34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = 'best_model.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 315us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1544689621244157, 0.5892857228006635]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embeddings_matrix_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
